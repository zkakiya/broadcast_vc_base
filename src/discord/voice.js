// src/discord/voice.js
// VCæ¥ç¶š â†’ ç™ºè©±æ¤œçŸ¥ â†’ Opusâ†’PCMâ†’WAV â†’ Whisper(Python) â†’ Discordé€ä¿¡ â†’ OBSå­—å¹•ãƒ—ãƒƒã‚·ãƒ¥
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import wav from 'wav';
import prism from 'prism-media';
import {
  joinVoiceChannel,
  entersState,
  VoiceConnectionStatus,
  EndBehaviorType,
} from '@discordjs/voice';

import { client, GUILD_ID, VOICE_CHANNEL_ID, TEXT_CHANNEL_ID } from './client.js';
import { transcribeAudioGPU } from './transcribe.js';
// index.js ã§ä½œã£ãŸ io ã‚’å—ã‘å–ã‚‹ styleï¼ˆå°†æ¥çš„é¸æŠè‚¢ï¼‰
let ioRef = null;
export function setIo(io) { ioRef = io; }
import { getSpeaker } from '../registry/speakers.js';
import { CONFIG } from '../config.js';
import { translateText } from '../utils/translate.js';

// --- ç¿»è¨³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆOpenAIå„ªå…ˆ / æœ€å°å®Ÿè£…ï¼‰ -----------------
const TRANSLATE_ENABLED = process.env.TRANSLATE_ENABLED === '1';
const TRANSLATE_TARGET_DEFAULT = process.env.TRANSLATE_TARGET_DEFAULT || ''; // ç©ºãªã‚‰å¾Œè¿°ã®è‡ªå‹•åˆ¤å®š
const hasOpenAI = !!process.env.OPENAI_API_KEY;

// __dirname (ESM)
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// éŒ²éŸ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ src/recordings ã«å›ºå®š
const recordingsDir = path.join(__dirname, '../recordings');
if (!fs.existsSync(recordingsDir)) fs.mkdirSync(recordingsDir, { recursive: true });

// â”€â”€ é‡è¤‡ç™ºç«/å¤šé‡é€ä¿¡ã‚¬ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const activeSessions = new Map();  // userId -> { closing: boolean }
const lastTexts = new Map();       // userId -> { text, ts }

// â”€â”€ Whisperç›´åˆ—å®Ÿè¡Œï¼ˆè² è·ã‚¹ãƒ‘ã‚¤ã‚¯æŠ‘åˆ¶ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let last = Promise.resolve();
function enqueue(task) {
  last = last.then(() => task()).catch(() => { }).finally(() => { });
  return last;
}

let currentConnection = null; // è¿½åŠ ï¼šç¾åœ¨ã®æ¥ç¶šã‚’ä¿æŒ

export async function joinAndRecordVC() {
  const guild = await client.guilds.fetch(GUILD_ID);
  if (!guild) throw new Error('Guild not found');

  const voiceChannel = await guild.channels.fetch(VOICE_CHANNEL_ID);
  if (!voiceChannel) throw new Error('Voice channel not found');

  if (currentConnection) {
    try { currentConnection.destroy(); } catch { }
    currentConnection = null;
  }

  let attempt = 0;
  const maxAttempts = 4;
  const baseDelay = 1500;
  let connection;

  while (attempt < maxAttempts) {
    attempt++;
    try {
      connection = joinVoiceChannel({
        channelId: voiceChannel.id,
        guildId: guild.id,
        adapterCreator: guild.voiceAdapterCreator,
        selfDeaf: false,
        selfMute: false,
      });

      currentConnection = connection; // ã“ã“ã§ä¿æŒ

      // ãƒ­ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
      connection.on('error', (err) => {
        console.error('[voice] connection error:', err?.message || err);
      });
      connection.on('stateChange', (oldS, newS) => {
        console.log(`[voice] state ${oldS.status} -> ${newS.status}`);
      });

      // æº–å‚™å®Œäº†ã‚’ä½™è£•ã‚’ã‚‚ã£ã¦å¾…ã¤
      await entersState(connection, VoiceConnectionStatus.Ready, 60_000);
      console.log('ğŸ§ Voice connection ready');
      break; // æˆåŠŸ
    } catch (e) {
      console.warn(`[voice] join attempt ${attempt} failed:`, e?.code || e?.message || e);
      try { connection?.destroy(); } catch { }
      if (attempt >= maxAttempts) throw e;
      const wait = baseDelay * Math.pow(2, attempt - 1); // 1.5s, 3s, 6s...
      await new Promise(r => setTimeout(r, wait));
      continue; // ãƒªãƒˆãƒ©ã‚¤
    }
  }
  const receiver = connection.receiver;
  receiver.speaking.setMaxListeners(100);

  receiver.speaking.on('start', (userIdRaw) => {
    const userId = String(userIdRaw);

    // æ—¢ã«éŒ²éŸ³ä¸­ãªã‚‰é‡è¤‡subscribeã‚’é˜²æ­¢
    if (activeSessions.has(userId)) return;
    activeSessions.set(userId, { closing: false });

    console.log(`ğŸ”Š ${userId} started speaking`);

    // ç„¡éŸ³ã—ãã„å€¤ï¼ˆmsï¼‰ã¯ç’°å¢ƒå¤‰æ•°ã§å¯å¤‰ã€‚æ—¢å®š600msï¼ˆå–ã‚Šã“ã¼ã—ä½æ¸›ï¼‰
    const SILENCE_MS = Number(process.env.VAD_SILENCE_MS || 600);
    const opusStream = receiver.subscribe(userId, {
      end: { behavior: EndBehaviorType.AfterSilence, duration: Number(process.env.VAD_SILENCE_MS || 600) },
    });

    opusStream.setMaxListeners(0);

    // ä¸€æ™‚WAV
    const wavPath = path.join(recordingsDir, `${userId}-${Date.now()}.wav`);

    // Opus â†’ PCM(48k/mono) â†’ WAV
    const decoder = new prism.opus.Decoder({ frameSize: 960, channels: 1, rate: 48000 });
    const wavWriter = new wav.FileWriter(wavPath, { sampleRate: 48000, channels: 1 });

    opusStream
      .on('error', (e) => console.error('opusStream error:', e))
      .pipe(decoder)
      .on('error', (e) => console.error('decoder error:', e))
      .pipe(wavWriter)
      .on('error', (e) => console.error('wavWriter error:', e));

    opusStream.once('end', async () => {
      // äºŒé‡closeé˜²æ­¢
      const s = activeSessions.get(userId);
      if (s?.closing) return;
      if (s) s.closing = true;

      console.log(`â¹ï¸ ${userId} presumed end of speech`);
      try { wavWriter.end(); } catch { }

      // FileWriter flush å¾…ã¡ï¼ˆå®‰å…¨ç­–ï¼‰
      setTimeout(async () => {
        try {
          // â˜… ã“ã“ã§å³åº§ã«é–‹æ”¾ï¼šæ¬¡ã®ç™ºè©±ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„
          activeSessions.delete(userId);

          // è©±è€…æƒ…å ±ã¯æœ€åˆã«å–å¾—ã—ã¦ä»¥é™ã§ä½¿ã†ï¼ˆTDZå›é¿ï¼‰
          const sp = getSpeaker(userId);

          // WAVã®æœ€å°é•·ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ48kHz/mono ãªã‚‰ 1ç§’ â‰’ 96KB + ãƒ˜ãƒƒãƒ€ï¼‰
          const st = fs.statSync(wavPath);
          const MIN_WAV_BYTES = Number(process.env.MIN_WAV_BYTES ?? 48000); // ç›®å®‰:0.5ç§’
          if (st.size < MIN_WAV_BYTES) {
            // çŸ­ã™ãã‚‹æ–­ç‰‡ã¯é™ã‹ã«ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ã‚°æŠ‘åˆ¶ã¯ç’°å¢ƒå¤‰æ•°ã§ï¼‰
            if (process.env.SHORT_WAV_LOG !== '0') {
              console.log(`(skip) short wav: ${st.size}B < ${MIN_WAV_BYTES}B`);
            }
            // å…ˆã«å‰Šé™¤ã—ã¦çµ‚äº†
            try { fs.unlinkSync(wavPath); } catch { }
            return; // â˜… ã“ã“ã§çµ‚ã‚ã‚Šï¼ˆthrowã—ãªã„ï¼‰
          }

          // Whisperã¯ç›´åˆ—å®Ÿè¡Œã§è² è·ã‚’å¹³æº–åŒ–
          const recognizedText = await enqueue(() => transcribeAudioGPU(wavPath));

          if (recognizedText && recognizedText.length) {
            // çŸ­æ™‚é–“ã®å®Œå…¨ä¸€è‡´ã¯é‡è¤‡ã¨ã—ã¦ç ´æ£„ï¼ˆã‚½ãƒ•ãƒˆãƒ»ãƒ‡ãƒ¥ãƒ¼ãƒ—ï¼‰
            const prev = lastTexts.get(userId);


            if (prev && prev.text === recognizedText && Date.now() - prev.ts < 3000) {
              return;
            }
            lastTexts.set(userId, { text: recognizedText, ts: Date.now() });

            // ã“ã“ã§å¿…è¦æƒ…å ±ã‚’â€œç¢ºå®šâ€ã—ã¦ãŠãï¼ˆIIFEå†…ã§ã¯ sp ã‚’ä½¿ã‚ãªã„ï¼‰
            const speakerName = sp?.name || 'Speaker';
            const speakerSide = sp?.side;
            const speakerColor = sp?.color;
            const speakerAvatar = sp?.avatar;
            const speakerIcon = sp?.icon;
            const translateTarget = sp?.translateTo || CONFIG?.translate?.defaultTarget;

            const msgId = `${userId}-${Date.now()}`;
            const payload = {
              id: msgId,
              userId,
              name: speakerName,
              side: speakerSide,
              color: speakerColor,
              avatar: speakerAvatar,
              icon: speakerIcon,
              text: recognizedText,
              lang: sp.lang || 'ja',
              ts: Date.now(),
            };
            if (ioRef) ioRef.emit('transcript', payload); // â˜… åŸæ–‡ã‚’å³æ™‚è¡¨ç¤º

            // 2) Discordãƒ†ã‚­ã‚¹ãƒˆã¸ï¼ˆã¾ãšåŸæ–‡ã ã‘é€ä¿¡ã€Messageã‚’ä¿æŒï¼‰
            try {
              const textChannel = await client.channels.fetch(TEXT_CHANNEL_ID);
              if (textChannel && textChannel.isTextBased()) {
                var sentMsg = await textChannel.send(`**${speakerName}**: ${recognizedText}`);
              } else {
                console.warn('Text channel not found or not text-based');
              }
            } catch (e) {
              console.error('âŒ Failed to send message:', e);
            }

            // 3) ç¿»è¨³ã¯å¾Œè¿½ã„ï¼ˆå¿…è¦æƒ…å ±ã¯ã™ã¹ã¦å¼•æ•°ã§æ¸¡ã™ï¼åŒã˜ try å†…ã§èµ·å‹•ï¼‰
            (async (origText, msgIdLocal, nameLocal, targetLocal, sentMsgLocal) => {
              try {
                if (!CONFIG?.translate?.enabled) return;
                if (!targetLocal) return; // é€ä¿¡å…ˆè¨€èªæœªè¨­å®šãªã‚‰ä½•ã‚‚ã—ãªã„
                const tr = await translateText({ text: origText, target: targetLocal });
                if (!tr) return;
                // é…ä¿¡ç”»é¢ã«è¿½è¨˜
                if (ioRef) ioRef.emit('transcript_update', { id: msgIdLocal, tr: { to: targetLocal, text: tr } });
                // Discord: åŸæ–‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç·¨é›†ã—ã¦è¨³ã‚’è¿½è¨˜
                if (sentMsgLocal) {
                  const newContent = `**${nameLocal}**\n${origText}\n> _${tr}_`;
                  try {
                    await sentMsgLocal.edit(newContent);
                  } catch {
                    // å¤±æ•—ã—ãŸã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§è¿½è¨˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    const ch = await client.channels.fetch(TEXT_CHANNEL_ID);
                    if (ch && ch.isTextBased()) await ch.send(`> _${tr}_`);
                  }
                }
              } catch (e) {
                console.warn('[translate async] failed:', e?.message || e);
              }
            })(recognizedText, msgId, speakerName, translateTarget, sentMsg);

          }
        } catch (e) {
          console.error('âŒ Whisper error:', e);
        } finally {
          // ä¸€æ™‚WAVã¯å¿…ãšå‰Šé™¤
          try {
            // ã™ã§ã«å‰Šé™¤æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆENOENTæŠ‘åˆ¶ï¼‰
            if (fs.existsSync(wavPath)) {
              fs.unlink(wavPath, (err) => {
                if (err && err.code !== 'ENOENT') console.warn('WAV delete failed:', err?.message);
              });
            }
          } catch { }
        }
      }, 100);
    });
  });
}
