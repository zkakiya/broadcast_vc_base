// src/discord/voice.js
// VCæ¥ç¶š â†’ ç™ºè©±æ¤œçŸ¥ â†’ Opusâ†’PCMâ†’WAV â†’ Whisper(Python) â†’ Discordé€ä¿¡ â†’ OBSå­—å¹•ãƒ—ãƒƒã‚·ãƒ¥
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import wav from 'wav';
import prism from 'prism-media';
import {
  joinVoiceChannel,
  entersState,
  VoiceConnectionStatus,
  EndBehaviorType,
} from '@discordjs/voice';

import { client, GUILD_ID, VOICE_CHANNEL_ID, TEXT_CHANNEL_ID } from './client.js';
import { transcribeAudioGPU } from './transcribe.js';
// index.js ã§ä½œã£ãŸ io ã‚’å—ã‘å–ã‚‹ styleï¼ˆå°†æ¥çš„é¸æŠè‚¢ï¼‰
let ioRef = null;
export function setIo(io) { ioRef = io; }
import { getSpeaker } from '../registry/speakers.js';

// --- ç¿»è¨³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆOpenAIå„ªå…ˆ / æœ€å°å®Ÿè£…ï¼‰ -----------------
const TRANSLATE_ENABLED = process.env.TRANSLATE_ENABLED === '1';
const TRANSLATE_TARGET_DEFAULT = process.env.TRANSLATE_TARGET_DEFAULT || ''; // ç©ºãªã‚‰å¾Œè¿°ã®è‡ªå‹•åˆ¤å®š
const hasOpenAI = !!process.env.OPENAI_API_KEY;

async function translateTextMinimal({ text, source, target }) {
  if (!TRANSLATE_ENABLED) return null;
  if (!text || !target || (source && source.toLowerCase() === target.toLowerCase())) return null;
  if (!hasOpenAI) return null; // â€»å¿…è¦ãªã‚‰ DeepL/Libre ã‚’è¶³ã›ã¾ã™
  try {
    const r = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        temperature: 0.2,
        messages: [
          { role: 'system', content: `You are a translator. Translate from ${source || 'auto'} to ${target}. Output only the translation.` },
          { role: 'user', content: text }
        ],
      }),
    });
    if (!r.ok) throw new Error(`OpenAI ${r.status}`);
    const j = await r.json();
    return j.choices?.[0]?.message?.content?.trim() || null;
  } catch (e) {
    console.warn('[translate] failed:', e?.message || e);
    return null;
  }
}

// __dirname (ESM)
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// éŒ²éŸ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ src/recordings ã«å›ºå®š
const recordingsDir = path.join(__dirname, '../recordings');
if (!fs.existsSync(recordingsDir)) fs.mkdirSync(recordingsDir, { recursive: true });

// â”€â”€ é‡è¤‡ç™ºç«/å¤šé‡é€ä¿¡ã‚¬ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const activeSessions = new Map();  // userId -> { closing: boolean }
const lastTexts = new Map();       // userId -> { text, ts }

// â”€â”€ Whisperç›´åˆ—å®Ÿè¡Œï¼ˆè² è·ã‚¹ãƒ‘ã‚¤ã‚¯æŠ‘åˆ¶ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let last = Promise.resolve();
function enqueue(task) {
  last = last.then(() => task()).catch(() => {}).finally(() => {});
  return last;
}

export async function joinAndRecordVC() {
  const guild = await client.guilds.fetch(GUILD_ID);
  if (!guild) throw new Error('Guild not found');

  const voiceChannel = await guild.channels.fetch(VOICE_CHANNEL_ID);
  if (!voiceChannel) throw new Error('Voice channel not found');

  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: guild.id,
    adapterCreator: guild.voiceAdapterCreator,
    selfDeaf: false,
    selfMute: false,
  });

  await entersState(connection, VoiceConnectionStatus.Ready, 30_000);
  console.log('ğŸ§ Voice connection ready');

  const receiver = connection.receiver;
  receiver.speaking.setMaxListeners(100);

  receiver.speaking.on('start', (userIdRaw) => {
    const userId = String(userIdRaw);

    // æ—¢ã«éŒ²éŸ³ä¸­ãªã‚‰é‡è¤‡subscribeã‚’é˜²æ­¢
    if (activeSessions.has(userId)) return;
    activeSessions.set(userId, { closing: false });

    console.log(`ğŸ”Š ${userId} started speaking`);

     // ç„¡éŸ³ã—ãã„å€¤ï¼ˆmsï¼‰ã¯ç’°å¢ƒå¤‰æ•°ã§å¯å¤‰ã€‚æ—¢å®š600msï¼ˆå–ã‚Šã“ã¼ã—ä½æ¸›ï¼‰
     const SILENCE_MS = Number(process.env.VAD_SILENCE_MS || 600);
     const opusStream = receiver.subscribe(userId, {
       end: { behavior: EndBehaviorType.AfterSilence, duration: Number(process.env.VAD_SILENCE_MS||600) },
     });

    opusStream.setMaxListeners(0);

    // ä¸€æ™‚WAV
    const wavPath = path.join(recordingsDir, `${userId}-${Date.now()}.wav`);

    // Opus â†’ PCM(48k/mono) â†’ WAV
    const decoder = new prism.opus.Decoder({ frameSize: 960, channels: 1, rate: 48000 });
    const wavWriter = new wav.FileWriter(wavPath, { sampleRate: 48000, channels: 1 });

    opusStream
      .on('error', (e) => console.error('opusStream error:', e))
      .pipe(decoder)
      .on('error', (e) => console.error('decoder error:', e))
      .pipe(wavWriter)
      .on('error', (e) => console.error('wavWriter error:', e));

    opusStream.once('end', async () => {
      // äºŒé‡closeé˜²æ­¢
      const s = activeSessions.get(userId);
      if (s?.closing) return;
      if (s) s.closing = true;

      console.log(`â¹ï¸ ${userId} presumed end of speech`);
      try { wavWriter.end(); } catch {}

      // FileWriter flush å¾…ã¡ï¼ˆå®‰å…¨ç­–ï¼‰
      setTimeout(async () => {
        try {
          // â˜… ã“ã“ã§å³åº§ã«é–‹æ”¾ï¼šæ¬¡ã®ç™ºè©±ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„
          activeSessions.delete(userId);

          // è©±è€…æƒ…å ±ã¯æœ€åˆã«å–å¾—ã—ã¦ä»¥é™ã§ä½¿ã†ï¼ˆTDZå›é¿ï¼‰
          const sp = getSpeaker(userId);

          // WAVã®æœ€å°é•·ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ48kHz/mono ãªã‚‰ 1ç§’ â‰’ 96KB + ãƒ˜ãƒƒãƒ€ï¼‰
          const st = fs.statSync(wavPath);
          const MIN_WAV_BYTES = Number(process.env.MIN_WAV_BYTES ?? 48000); // ç›®å®‰:0.5ç§’
          let alreadyDeleted = false;
          if (st.size < MIN_WAV_BYTES) {
            // çŸ­ã™ãã‚‹æ–­ç‰‡ã¯é™ã‹ã«ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ã‚°æŠ‘åˆ¶ã¯ç’°å¢ƒå¤‰æ•°ã§ï¼‰
            if (process.env.SHORT_WAV_LOG !== '0') {
              console.log(`(skip) short wav: ${st.size}B < ${MIN_WAV_BYTES}B`);
            }
            // å‰Šé™¤ã¯ finally ã«ä»»ã›ãšã€ã“ã“ã§è¡Œã† â†’ äºŒé‡å‰Šé™¤é˜²æ­¢ã®ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
            try { fs.unlinkSync(wavPath); alreadyDeleted = true; } catch {}
            return; // â˜… ã“ã“ã§çµ‚ã‚ã‚Šï¼ˆthrowã—ãªã„ï¼‰
          }

          // Whisperã¯ç›´åˆ—å®Ÿè¡Œã§è² è·ã‚’å¹³æº–åŒ–
          const text = await enqueue(() => transcribeAudioGPU(wavPath));

          if (text && text.length) {
            // çŸ­æ™‚é–“ã®å®Œå…¨ä¸€è‡´ã¯é‡è¤‡ã¨ã—ã¦ç ´æ£„ï¼ˆã‚½ãƒ•ãƒˆãƒ»ãƒ‡ãƒ¥ãƒ¼ãƒ—ï¼‰
            const prev = lastTexts.get(userId);

            // ç¿»è¨³å…ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼šæ˜ç¤ºï¼ˆenvï¼‰> è‡ªå‹•ï¼ˆè©±è€…langãŒjaãªã‚‰enã€ãã†ã§ãªã‘ã‚Œã°jaï¼‰
            const targetLang =
              TRANSLATE_TARGET_DEFAULT ||
              ((sp.lang || 'ja').toLowerCase() === 'ja' ? 'en' : 'ja');
            const trText = await translateTextMinimal({
              text,
              source: sp.lang || undefined,
              target: targetLang,
            });

            if (prev && prev.text === text && Date.now() - prev.ts < 3000) {
              return;
            }
            lastTexts.set(userId, { text, ts: Date.now() });

            const payload = {
              id: `${userId}-${Date.now()}`,
              userId,
              name: sp.name,
              side: sp.side,
              color: sp.color,
              avatar: sp.avatar,
              icon: sp.icon, 
              text,
              lang: sp.lang || 'ja',
              ts: Date.now(),
              // ç¿»è¨³ï¼ˆã‚ã‚Œã°ï¼‰
              ...(trText ? { tr: { lang: targetLang, text: trText } } : {}),
            };

            // 1) OBSå­—å¹•ãƒšãƒ¼ã‚¸ã¸
            if (ioRef) {
              ioRef.emit('transcript', payload);
            } else {
              console.warn('[socket] ioRef is not set; skipped emit');
            }
            // 2) Discordãƒ†ã‚­ã‚¹ãƒˆã¸
            try {
              const textChannel = await client.channels.fetch(TEXT_CHANNEL_ID);
              if (textChannel && textChannel.isTextBased()) {
                if (trText) {
                  await textChannel.send(`**${sp.name}**\n${text}\n> _${trText}_`);
                } else {
                  await textChannel.send(`**${sp.name}**: ${text}`);
                }
               } else {
                console.warn('Text channel not found or not text-based');
              }
            } catch (e) {
              console.error('âŒ Failed to send message:', e);
            }
          }
        } catch (e) {
          console.error('âŒ Whisper error:', e);
        } finally {
          // ä¸€æ™‚WAVã¯å¿…ãšå‰Šé™¤
          try {
            // ã™ã§ã«å‰Šé™¤æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆENOENTæŠ‘åˆ¶ï¼‰
            if (fs.existsSync(wavPath)) {
              fs.unlink(wavPath, (err) => {
                if (err && err.code !== 'ENOENT') console.warn('WAV delete failed:', err?.message);
              });
            }
          } catch {}
        }
      }, 100);
    });
  });
}
